{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from py2neo import *\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "from nltk import pos_tag\n",
    "from itertools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    global graph\n",
    "    graph = Graph(\"bolt://localhost:7687\", auth = (\"neo4j\", \"soham\"))\n",
    "    tx = graph.begin()\n",
    "    print('Connected...')\n",
    "connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question():\n",
    "    global question\n",
    "    question = input(\"INPUT: \")\n",
    "    print(\"\\n\")\n",
    "    tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenize():\n",
    "    global filtered_question\n",
    "    question_tokenized = word_tokenize(question)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_question = [w for w in question_tokenized if not w in stop_words]\n",
    "    filtered_question = []\n",
    "    for w in question_tokenized:\n",
    "        if w not in stop_words:\n",
    "            filtered_question.append(w)\n",
    "    tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tag():\n",
    "    global ner, tags\n",
    "    nlp = en_core_web_sm.load()\n",
    "    doc = nlp(question)\n",
    "    ner = [(X.text, X.label_) for X in doc.ents]\n",
    "    print(question)\n",
    "    print(filtered_question)\n",
    "    for token in doc:\n",
    "        print((token.text, token.pos_, token.tag_, token.dep_))\n",
    "    displacy.render(doc)\n",
    "    tags = pos_tag(filtered_question)\n",
    "    print('All tags: ',tags)\n",
    "    print('Length of the list: ',len(tags))\n",
    "    groups = groupby(tags, key=lambda x: x[1])\n",
    "    names_tagged = [[w for w,_ in words] for tag,words in groups if tag==\"NNP\"]\n",
    "    print('Tagged names are: ',names_tagged)\n",
    "    names = [\" \".join(name) for name in names_tagged if len(name)>=2]\n",
    "    parms_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parms_builder():\n",
    "    global parms, parms_2\n",
    "    if len(ner) == 1:\n",
    "        if (ner[0][1] == 'GPE') or (ner[0][1] == 'LOC'):\n",
    "            if (ner[0][0] == \"US\") or (ner[0][0] == \"USA\"):\n",
    "                country_ = 'United States'\n",
    "            elif (ner[0][0] == \"UK\"):\n",
    "                country_ = 'United Kingdom'\n",
    "            else:\n",
    "                country = ner[0][0]\n",
    "                parms = {}\n",
    "                parms[\"country\"] = country\n",
    "                print(parms)\n",
    "        elif (ner[0][1] == 'ORG'):\n",
    "            org = ner[0][0]\n",
    "            parms = {}\n",
    "            parms[\"org\"] = org\n",
    "            print(parms)\n",
    "        elif (ner[0][1] == 'PERSON'):\n",
    "            person = ner[0][0]\n",
    "            parms = {}\n",
    "            parms[\"person\"] = person\n",
    "            print(parms)\n",
    "    elif len(ner) > 1:\n",
    "        name1 = ner[0][0]\n",
    "        name2 = ner[1][0]\n",
    "        parms_2 = {\"name1\":name1, \"name2\":name2}\n",
    "        print(parms_2)\n",
    "    query_picker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def query_picker():\n",
    "    \n",
    "    label_p = \"(p:NER_Person)\"\n",
    "    label_o = \"(o:NER_Organization)\"\n",
    "    label_l = \"(l:NER_Location)\"\n",
    "    works = \"-[r:WORKS_AT]->\"\n",
    "    lives = \"-[:LIVES_IN]->\"\n",
    "\n",
    "    query1 = '''\n",
    "    match {} {} {}\n",
    "    where p.value IN $person\n",
    "    return p.value as Name,r.value as Works_as,o.value as at\n",
    "    '''.format(label_p,works,label_o)\n",
    "\n",
    "    query1_1 = '''\n",
    "    match {} {} {}\n",
    "    where o.value IN $org\n",
    "    return o.value as Organization, collect(distinct p.value) as Person, r.value as Position\n",
    "    '''.format(label_p,works,label_o)\n",
    "\n",
    "    query2 = '''\n",
    "    match (p:NER_Person{value:$person})-[r:LIVES_IN]-(l:NER_Location)\n",
    "    return p.value as Person, l.value as STAYS_AT\n",
    "    '''\n",
    "\n",
    "    query3 = '''\n",
    "    MATCH (p1:NER_Person:Tag{ value: $name1 }),(p2:NER_Person:Tag{ value: $name2 }), p = shortestPath((p1)-[*..15]-(p2))\n",
    "    RETURN p1.value as Person1, p2.value as Person2, p as Relation\n",
    "    '''\n",
    "\n",
    "    query4 = '''\n",
    "    MATCH (p:NER_Person)-[w:LIVES_IN]->(o:NER_Location)\n",
    "    RETURN p.value as Person ,o.value as Lives_in\n",
    "    '''.format(label_p,lives,label_o)\n",
    "\n",
    "    query5 = '''\n",
    "    MATCH (p:NER_Person)-[:LIVES_IN]->(l:NER_Location), (p)-[w:WORKS_AT]-(o:NER_Organization)\n",
    "    RETURN p.value as Person, l.value as Lives_in, o.value as Works_at, w.AS as Position\n",
    "    '''\n",
    "\n",
    "    query6 = '''\n",
    "    MATCH (s:Sentence)-[st:SENTENCE_TAG_OCCURRENCE]->(n:TagOccurrence), (s)-[h:HAS_TAG]-(p:NER_Person), (s)-[h]-(o:NER_Organization)\n",
    "    where n.value IN [\"said\",\"says\",\"think\",\"thinks\"] AND (p.value in $names OR o.value in $org)\n",
    "    return s.text as Sentence, p.value as Person\n",
    "    '''\n",
    "    for word,tag in tags:\n",
    "        if word in ['work','do']:\n",
    "            verb = word\n",
    "            query = query1\n",
    "            print('We have a verb: ',verb)\n",
    "            print(query)\n",
    "            print(graph.run(query,parms).data())\n",
    "        elif word in ['works','at']:\n",
    "            verb = word\n",
    "            print('We have an org: ',word)\n",
    "            print(graph.run(query1_1,parms).to_table())\n",
    "        elif word in ['live','reside','stay']:\n",
    "            verb = word\n",
    "            print('We have a verb: ',verb)\n",
    "            print(graph.run(query2,parms).data())\n",
    "        elif word in ['related','relation']:\n",
    "            verb = word\n",
    "            print('We have a verb: ',verb)\n",
    "            print(graph.run(query3,parms_2).data())\n",
    "        elif word in ['lives']:\n",
    "            verb = word\n",
    "            print('We have a verb: ',verb)\n",
    "            print(graph.run(query4).to_table())\n",
    "        elif word in ['everyone']:\n",
    "            verb = word\n",
    "            print('We have a verb (s): ',verb)\n",
    "            print(graph.run(query5).to_table()) \n",
    "        elif word in ['think', 'says', 'say']:\n",
    "            verb = word\n",
    "            print('We have a verb: ',verb)\n",
    "            print(graph.run(query6,parms).to_table()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
